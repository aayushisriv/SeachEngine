{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import glob\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import re\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from nltk import sent_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk import map_tag\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans \n",
    "import pylab as pl\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.metrics import confusion_matrix\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFiles = glob.glob(\"C:\\*.txt\")#get the paper names,matching text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\icse_id.txt', 'C:\\\\vldb_id.txt']\n"
     ]
    }
   ],
   "source": [
    "print(allFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = pd.DataFrame()\n",
    "list_ = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,delimiter='\\t')\n",
    "    df.columns = ['id','title','title_small','year','date','unnamed','conference','conference_short','reference1','reference2','reference3']\n",
    "    list_.append(df)\n",
    "frame = pd.concat(list_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id                                              title  \\\n",
      "0     766984B4          Co-Operative Method Development revisited   \n",
      "1     7F5DB806             An integrated bug processing framework   \n",
      "2     78F1E9FF  Guest Editorial: Introduction to the Special S...   \n",
      "3     7D6EB553  Optimizing symbolic model checking for statech...   \n",
      "4     7FBCB0CC    Supporting search for reusable software objects   \n",
      "5     790C5919  Identification of dynamic comprehension proces...   \n",
      "6     7FEC4901  Completeness and consistency in hierarchical s...   \n",
      "7     76B250FB  Guest editors' introduction: 1999 internationa...   \n",
      "8     777166C0  Effectiveness Evaluation of Command and Contro...   \n",
      "9     7B1A023C  Cloudlet-based cyber-foraging for mobile syste...   \n",
      "10    7B583E24         An operating system development: Windows 3   \n",
      "11    7811B21C  Representing Unique Stakeholder Perspectives i...   \n",
      "12    7E90C370  Specification patterns from research to indust...   \n",
      "13    8553A067  Automated Energy Optimization of HTTP Requests...   \n",
      "14    7635A59A  The improvement of GAC model for image segment...   \n",
      "15    7D1BC7D0            Generative techniques for product lines   \n",
      "16    7D8A0D37  Modular-Like Transformations and Style Checkin...   \n",
      "17    817DF2C7  The universal design solution for Ajax-based t...   \n",
      "18    79CD68C3                     Service-Oriented Message Queue   \n",
      "19    7E611FAE  Semi-automatically extracting FAQs to improve ...   \n",
      "20    80036B58  Calculating architectural reliability via mode...   \n",
      "21    7D8A0202  Summary for scrutinizing agile practices or sh...   \n",
      "22    7FFFB0C7  Reengineering analysis of object-oriented syst...   \n",
      "23    7EAE63BC  Enhancing program readability and comprehensib...   \n",
      "24    7B094121  A specification-based adaptive test case gener...   \n",
      "25    0C038917  Ontology for complex railway systems applicati...   \n",
      "26    7D9E60BF  Modular modelling of software product lines wi...   \n",
      "27    7945747F  Code Generation on Steroids: Enhancing COTS Co...   \n",
      "28    7A340F2C  The SCR method for formally specifying, verify...   \n",
      "29    7A42BE3A  Combining mastery learning with project-based ...   \n",
      "...        ...                                                ...   \n",
      "4293  0A36043B  Dan Suciu: Declarative Specification of Web Si...   \n",
      "4294  7F3E3FD2  Distinct Sampling for Highly-Accurate Answers ...   \n",
      "4295  058FF590             Coexistence and transformation of data   \n",
      "4296  5D999AE0  Commutativity and its role in the processing o...   \n",
      "4297  5D32807D              Semantic Data Caching and Replacement   \n",
      "4298  5D4B8B24  Selectivity Estimation in Extensible Databases...   \n",
      "4299  5E0E7E2E  Data Abstraction, Databases and Conceptual Mod...   \n",
      "4300  050A1BCA    Semantics vs. graphics - to show or not to show   \n",
      "4301  5F7AC1B9  Hash Joins and Hash Teams in Microsoft SQL Server   \n",
      "4302  5F5B8438  MARS: a system for publishing XML from mixed a...   \n",
      "4303  80F2069D  Detecting anomalous access patterns in relatio...   \n",
      "4304  80BF4FCC                          Type-based XML projection   \n",
      "4305  811116A9  Minimizing The I/O-Operations For Undo-Logging...   \n",
      "4306  5EBDCB26  Diag-Join: An Opportunistic Join Algorithm for...   \n",
      "4307  810B734A                          Sorting networks on FPGAs   \n",
      "4308  5F826E54  A family of incomplete relational database models   \n",
      "4309  02515A15  The Impact of New Technologies on the Architec...   \n",
      "4310  5F37FB69      On the marriage of Lp-norms and edit distance   \n",
      "4311  5FBB44B8  A Study of Sort Algorithms for Multiprocessor ...   \n",
      "4312  5EE4DAD6            Characteristics of Scientific Databases   \n",
      "4313  75D8F205  UnQL: a query language and algebra for semistr...   \n",
      "4314  053155E6                  A DBS Platform for Bioinformatics   \n",
      "4315  58AF95BD  COMBI-operator - database support for data min...   \n",
      "4316  5B1F0442  A Theory of Timestamp-Based Concurrency Contro...   \n",
      "4317  0694FCE4  Rajeev Rastogi: RE-Tree: An Efficient Index St...   \n",
      "4318  59AFE526  Panel: Future Directions of Database Research ...   \n",
      "4319  7CA3A7CF  On the encipherment of search trees and random...   \n",
      "4320  78572C5C  ACM transactions on database systems: aim and ...   \n",
      "4321  7F97FCF2  The entity-relationship model—toward a unified...   \n",
      "4322  8170089D                Data Integration Using Web Services   \n",
      "\n",
      "                                            title_small  year        date  \\\n",
      "0             co operative method development revisited  2005  2005/05/16   \n",
      "1                an integrated bug processing framework  2012  2012/06/02   \n",
      "2     guest editorial introduction to the special se...  1998  1998/09/01   \n",
      "3     optimizing symbolic model checking for statech...  2001     2001/02   \n",
      "4       supporting search for reusable software objects  1996     1996/06   \n",
      "5     identification of dynamic comprehension proces...  1996     1996/06   \n",
      "6     completeness and consistency in hierarchical s...  1996     1996/06   \n",
      "7     guest editors introduction 1999 international ...  2001     2001/02   \n",
      "8     effectiveness evaluation of command and contro...  2014  2014/03/27   \n",
      "9     cloudlet based cyber foraging for mobile syste...  2014  2014/05/31   \n",
      "10            an operating system development windows 3  1996  1996/05/01   \n",
      "11    representing unique stakeholder perspectives i...  2010     2010/05   \n",
      "12    specification patterns from research to indust...  2012  2012/06/02   \n",
      "13    automated energy optimization of http requests...  2016        2016   \n",
      "14    the improvement of gac model for image segment...  2013     2013/05   \n",
      "15              generative techniques for product lines  2001  2001/07/01   \n",
      "16    modular like transformations and style checkin...  2007  2007/05/20   \n",
      "17    the universal design solution for ajax based t...  2015     2015/09   \n",
      "18                       service oriented message queue  2014  2014/03/27   \n",
      "19    semi automatically extracting faqs to improve ...  2012  2012/06/02   \n",
      "20    calculating architectural reliability via mode...  2004  2004/05/23   \n",
      "21    summary for scrutinizing agile practices or sh...  2008  2008/05/10   \n",
      "22    reengineering analysis of object oriented syst...  2001  2001/07/01   \n",
      "23    enhancing program readability and comprehensib...  1988  1988/04/01   \n",
      "24    a specification based adaptive test case gener...  1996  1996/05/01   \n",
      "25    ontology for complex railway systems applicati...  2013        2013   \n",
      "26    modular modelling of software product lines wi...  2011  2011/11/14   \n",
      "27    code generation on steroids enhancing cots cod...  2007  2007/05/20   \n",
      "28    the scr method for formally specifying verifyi...  1997  1997/05/01   \n",
      "29    combining mastery learning with project based ...  2015  2015/05/16   \n",
      "...                                                 ...   ...         ...   \n",
      "4293  dan suciu declarative specification of web sit...  2000         NaN   \n",
      "4294  distinct sampling for highly accurate answers ...  2001  2001/09/11   \n",
      "4295             coexistence and transformation of data  1977  1977/10/06   \n",
      "4296  commutativity and its role in the processing o...  1989  1989/07/01   \n",
      "4297              semantic data caching and replacement  1996  1996/09/03   \n",
      "4298  selectivity estimation in extensible databases...  1998  1998/08/24   \n",
      "4299  data abstraction databases and conceptual mode...  1980         NaN   \n",
      "4300       semantics vs graphics to show or not to show  1980  1980/10/01   \n",
      "4301  hash joins and hash teams in microsoft sql server  1998  1998/08/24   \n",
      "4302  mars a system for publishing xml from mixed an...  2003  2003/09/09   \n",
      "4303  detecting anomalous access patterns in relatio...  2008  2008/08/01   \n",
      "4304                          type based xml projection  2006  2006/09/01   \n",
      "4305  minimizing the i o operations for undo logging...  1979        1979   \n",
      "4306  diag join an opportunistic join algorithm for ...  1998  1998/08/24   \n",
      "4307                          sorting networks on fpgas  2012  2012/02/01   \n",
      "4308  a family of incomplete relational database models  1989  1989/07/01   \n",
      "4309  the impact of new technologies on the architec...  1978         NaN   \n",
      "4310      on the marriage of lp norms and edit distance  2004  2004/08/31   \n",
      "4311  a study of sort algorithms for multiprocessor ...  1986  1986/08/25   \n",
      "4312            characteristics of scientific databases  1984  1984/08/27   \n",
      "4313  unql a query language and algebra for semistru...  2000  2000/03/01   \n",
      "4314                  a dbs platform for bioinformatics  2000         NaN   \n",
      "4315  combi operator database support for data minin...  2003  2003/09/09   \n",
      "4316  a theory of timestamp based concurrency contro...  1988  1988/08/29   \n",
      "4317  rajeev rastogi re tree an efficient index stru...  2002         NaN   \n",
      "4318  panel future directions of database research t...  2000  2000/09/10   \n",
      "4319  on the encipherment of search trees and random...  1976  1976/03/01   \n",
      "4320  acm transactions on database systems aim and s...  1976  1976/03/01   \n",
      "4321  the entity relationship model toward a unified...  1976  1976/03/01   \n",
      "4322                data integration using web services  2003  2003/01/01   \n",
      "\n",
      "                               unnamed  \\\n",
      "0                                  NaN   \n",
      "1            10.1109/ICSE.2012.6227060   \n",
      "2                                  NaN   \n",
      "3                    10.1109/32.908961   \n",
      "4                    10.1109/32.508314   \n",
      "5                    10.1109/32.508315   \n",
      "6                    10.1109/32.508311   \n",
      "7              10.1109/TSE.2001.908956   \n",
      "8                                  NaN   \n",
      "9              10.1145/2591062.2591119   \n",
      "10                                 NaN   \n",
      "11                10.1109/SERA.2010.16   \n",
      "12           10.1109/ICSE.2012.6227125   \n",
      "13                                 NaN   \n",
      "14         10.1109/ICSESS.2013.6615480   \n",
      "15            10.1109/ICSE.2001.919165   \n",
      "16       10.1109/ICSECOMPANION.2007.55   \n",
      "17                                 NaN   \n",
      "18                                 NaN   \n",
      "19                                 NaN   \n",
      "20           10.1109/ICSE.2004.1317426   \n",
      "21             10.1145/1370175.1370232   \n",
      "22            10.1109/ICSE.2001.919132   \n",
      "23             10.1109/ICSE.1988.93716   \n",
      "24            10.1109/ICSE.1996.493404   \n",
      "25                                 NaN   \n",
      "26        10.1007/978-3-642-24690-6_22   \n",
      "27                                 NaN   \n",
      "28            10.1109/ICSE.1997.610430   \n",
      "29                                 NaN   \n",
      "...                                ...   \n",
      "4293                               NaN   \n",
      "4294                               NaN   \n",
      "4295                               NaN   \n",
      "4296                               NaN   \n",
      "4297                               NaN   \n",
      "4298                               NaN   \n",
      "4299                               NaN   \n",
      "4300                               NaN   \n",
      "4301                               NaN   \n",
      "4302  10.1016/B978-012722442-8/50026-4   \n",
      "4303         10.1007/s00778-007-0051-4   \n",
      "4304                               NaN   \n",
      "4305                               NaN   \n",
      "4306                               NaN   \n",
      "4307         10.1007/s00778-011-0232-z   \n",
      "4308                               NaN   \n",
      "4309                               NaN   \n",
      "4310                               NaN   \n",
      "4311                               NaN   \n",
      "4312                               NaN   \n",
      "4313                               NaN   \n",
      "4314                               NaN   \n",
      "4315  10.1016/B978-012722442-8/50045-8   \n",
      "4316                               NaN   \n",
      "4317                               NaN   \n",
      "4318                               NaN   \n",
      "4319             10.1145/320434.320445   \n",
      "4320                               NaN   \n",
      "4321             10.1145/320434.320440   \n",
      "4322          10.1007/3-540-36556-7_15   \n",
      "\n",
      "                                            conference conference_short  \\\n",
      "0     international conference on software engineering             icse   \n",
      "1     international conference on software engineering             icse   \n",
      "2     international conference on software engineering             icse   \n",
      "3     international conference on software engineering             icse   \n",
      "4     international conference on software engineering             icse   \n",
      "5     international conference on software engineering             icse   \n",
      "6     international conference on software engineering             icse   \n",
      "7     international conference on software engineering             icse   \n",
      "8     international conference on software engineering             icse   \n",
      "9     international conference on software engineering             icse   \n",
      "10    international conference on software engineering             icse   \n",
      "11    international conference on software engineering             icse   \n",
      "12    international conference on software engineering             icse   \n",
      "13    international conference on software engineering             icse   \n",
      "14    international conference on software engineering             icse   \n",
      "15    international conference on software engineering             icse   \n",
      "16    international conference on software engineering             icse   \n",
      "17    international conference on software engineering             icse   \n",
      "18    international conference on software engineering             icse   \n",
      "19    international conference on software engineering             icse   \n",
      "20    international conference on software engineering             icse   \n",
      "21    international conference on software engineering             icse   \n",
      "22    international conference on software engineering             icse   \n",
      "23    international conference on software engineering             icse   \n",
      "24    international conference on software engineering             icse   \n",
      "25    international conference on software engineering             icse   \n",
      "26    international conference on software engineering             icse   \n",
      "27    international conference on software engineering             icse   \n",
      "28    international conference on software engineering             icse   \n",
      "29    international conference on software engineering             icse   \n",
      "...                                                ...              ...   \n",
      "4293                             very large data bases             vldb   \n",
      "4294                             very large data bases             vldb   \n",
      "4295                             very large data bases             vldb   \n",
      "4296                             very large data bases             vldb   \n",
      "4297                             very large data bases             vldb   \n",
      "4298                             very large data bases             vldb   \n",
      "4299                             very large data bases             vldb   \n",
      "4300                             very large data bases             vldb   \n",
      "4301                             very large data bases             vldb   \n",
      "4302                             very large data bases             vldb   \n",
      "4303                             very large data bases             vldb   \n",
      "4304                             very large data bases             vldb   \n",
      "4305                             very large data bases             vldb   \n",
      "4306                             very large data bases             vldb   \n",
      "4307                             very large data bases             vldb   \n",
      "4308                             very large data bases             vldb   \n",
      "4309                             very large data bases             vldb   \n",
      "4310                             very large data bases             vldb   \n",
      "4311                             very large data bases             vldb   \n",
      "4312                             very large data bases             vldb   \n",
      "4313                             very large data bases             vldb   \n",
      "4314                             very large data bases             vldb   \n",
      "4315                             very large data bases             vldb   \n",
      "4316                             very large data bases             vldb   \n",
      "4317                             very large data bases             vldb   \n",
      "4318                             very large data bases             vldb   \n",
      "4319                             very large data bases             vldb   \n",
      "4320                             very large data bases             vldb   \n",
      "4321                             very large data bases             vldb   \n",
      "4322                             very large data bases             vldb   \n",
      "\n",
      "     reference1 reference2  reference3  \n",
      "0      0B24320F   45FFFB88       19176  \n",
      "1      0A0407AE   45FFFB88       19555  \n",
      "2      007F6F5E   45FFFB88       19404  \n",
      "3      007F6F5E   45FFFB88       18725  \n",
      "4      007F6F5E   45FFFB88       17872  \n",
      "5      007F6F5E   45FFFB88       16979  \n",
      "6      007F6F5E   45FFFB88       16558  \n",
      "7      007F6F5E   45FFFB88       19555  \n",
      "8           NaN   45FFFB88       19555  \n",
      "9           NaN   45FFFB88       19272  \n",
      "10          NaN   45FFFB88       19555  \n",
      "11          NaN   45FFFB88       17417  \n",
      "12          NaN   45FFFB88       19087  \n",
      "13          NaN   45FFFB88       19555  \n",
      "14          NaN   45FFFB88       19555  \n",
      "15          NaN   45FFFB88       19192  \n",
      "16          NaN   45FFFB88       19337  \n",
      "17          NaN   45FFFB88       19555  \n",
      "18          NaN   45FFFB88       19555  \n",
      "19          NaN   45FFFB88       19048  \n",
      "20          NaN   45FFFB88       19119  \n",
      "21          NaN   45FFFB88       19555  \n",
      "22          NaN   45FFFB88       18967  \n",
      "23          NaN   45FFFB88       18665  \n",
      "24          NaN   45FFFB88       19245  \n",
      "25          NaN   45FFFB88       19555  \n",
      "26          NaN   45FFFB88       19314  \n",
      "27          NaN   45FFFB88       17569  \n",
      "28          NaN   45FFFB88       18375  \n",
      "29          NaN   45FFFB88       19476  \n",
      "...         ...        ...         ...  \n",
      "4293   04B4543D   4390334E       17446  \n",
      "4294   04B4543D   4390334E       16950  \n",
      "4295   04B4543D   4390334E       17391  \n",
      "4296   04B4543D   4390334E       19468  \n",
      "4297   04B4543D   4390334E       16029  \n",
      "4298   04B4543D   4390334E       19433  \n",
      "4299   04B4543D   4390334E       17580  \n",
      "4300   04B4543D   4390334E       17635  \n",
      "4301   04B4543D   4390334E       17695  \n",
      "4302   04B4543D   4390334E       17565  \n",
      "4303   04B4543D   4390334E       18259  \n",
      "4304   04B4543D   4390334E       18238  \n",
      "4305   04B4543D   4390334E       18670  \n",
      "4306   04B4543D   4390334E       18467  \n",
      "4307   04B4543D   4390334E       18778  \n",
      "4308   04B4543D   4390334E       18829  \n",
      "4309   04B4543D   4390334E       19555  \n",
      "4310   04B4543D   4390334E       17045  \n",
      "4311   04B4543D   4390334E       17186  \n",
      "4312   04B4543D   4390334E       16194  \n",
      "4313   04B4543D   4390334E       16879  \n",
      "4314   04B4543D   4390334E       19555  \n",
      "4315   04B4543D   4390334E       18765  \n",
      "4316   04B4543D   4390334E       18373  \n",
      "4317   04B4543D   4390334E       19555  \n",
      "4318   04B4543D   4390334E       18967  \n",
      "4319   055F1F1C   4390334E       18680  \n",
      "4320   055F1F1C   4390334E       17076  \n",
      "4321   055F1F1C   4390334E       19513  \n",
      "4322   039EACD9   4390334E       19505  \n",
      "\n",
      "[14408 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print((frame))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf__max_df: (0.25, 0.50, 0.75)#removing words that appear too frequently in documents\n",
    "tfidf__ngram_range: ((1, 1), (1, 2), (1, 3))#ngram_range parameter selects how large are the sequences of words to be considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Co-Operative Method Development revisited']\n",
      " ['An integrated bug processing framework']\n",
      " ['Guest Editorial: Introduction to the Special Section']\n",
      " ...\n",
      " ['ACM transactions on database systems: aim and scope']\n",
      " ['The entity-relationship model—toward a unified view of data']\n",
      " ['Data Integration Using Web Services']]\n",
      "[['icse']\n",
      " ['icse']\n",
      " ['icse']\n",
      " ...\n",
      " ['vldb']\n",
      " ['vldb']\n",
      " ['vldb']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#split the d\n",
    "data_x = frame[['title']].as_matrix()\n",
    "print(data_x)\n",
    "data_y = frame[['conference_short']].as_matrix()\n",
    "print(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['icse']\n",
      " ['vldb']\n",
      " ['icse']\n",
      " ...\n",
      " ['icse']\n",
      " ['vldb']\n",
      " ['icse']]\n"
     ]
    }
   ],
   "source": [
    "stratified_split = StratifiedShuffleSplit(n_splits=2, test_size=0.33)\n",
    "for train_index, test_index in stratified_split.split(data_x, data_y):\n",
    "    x_train, x_test = data_x[train_index], data_x[test_index]\n",
    "    y_train, y_test = data_y[train_index], data_y[test_index]\n",
    "train_x = [x[0].strip() for x in x_train.tolist()]\n",
    "test_x = [x[0].strip() for x in x_test.tolist()]\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_NB = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "        fit_prior=True, class_prior=None))),\n",
    "])\n",
    "parameters_NB = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'clf_estimator_alpha': (1e-2, 1e-3)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 18 candidates, totalling 36 fits\n"
     ]
    },
    {
     "ename": "JoblibValueError",
     "evalue": "JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x00000263054A2F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-p...ges\\__pycache__\\ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\a...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x00000263054A2F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-p...ges\\__pycache__\\ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\a...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    494         if self.poller is not None:\n    495             self.poller.start()\n    496         self.kernel.start()\n    497         self.io_loop = ioloop.IOLoop.current()\n    498         try:\n--> 499             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    500         except KeyboardInterrupt:\n    501             pass\n    502 \n    503 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    518         sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    519                                finalizer=self._asyncgen_finalizer_hook)\n    520         try:\n    521             events._set_running_loop(self)\n    522             while True:\n--> 523                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    524                 if self._stopping:\n    525                     break\n    526         finally:\n    527             self._stopping = False\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1753                         logger.warning('Executing %s took %.3f seconds',\n   1754                                        _format_handle(handle), dt)\n   1755                 finally:\n   1756                     self._current_handle = None\n   1757             else:\n-> 1758                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(512, 1)>>\n   1759         handle = None  # Needed to break cycles when an exception occurs.\n   1760 \n   1761     def _set_coroutine_origin_tracking(self, enabled):\n   1762         if bool(enabled) == bool(self._coroutine_origin_tracking_enabled):\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(512, 1)>)\n     83     def cancelled(self):\n     84         return self._cancelled\n     85 \n     86     def _run(self):\n     87         try:\n---> 88             self._context.run(self._callback, *self._args)\n        self._context.run = <built-in method run of Context object>\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (512, 1)\n     89         except Exception as exc:\n     90             cb = format_helpers._format_callback_source(\n     91                 self._callback, self._args)\n     92             msg = f'Exception in callback {cb}'\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=512, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 28, 2, 38, 49, 932857, tzinfo=tzutc()), 'msg_id': '99c90725bb674a8b811a39cebaebfc3a', 'msg_type': 'execute_request', 'session': 'd1417ed41c9c43b6af31277b610f6eb2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '99c90725bb674a8b811a39cebaebfc3a', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'd1417ed41c9c43b6af31277b610f6eb2']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 28, 2, 38, 49, 932857, tzinfo=tzutc()), 'msg_id': '99c90725bb674a8b811a39cebaebfc3a', 'msg_type': 'execute_request', 'session': 'd1417ed41c9c43b6af31277b610f6eb2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '99c90725bb674a8b811a39cebaebfc3a', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'd1417ed41c9c43b6af31277b610f6eb2'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 28, 2, 38, 49, 932857, tzinfo=tzutc()), 'msg_id': '99c90725bb674a8b811a39cebaebfc3a', 'msg_type': 'execute_request', 'session': 'd1417ed41c9c43b6af31277b610f6eb2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '99c90725bb674a8b811a39cebaebfc3a', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-61-9bd2d6d04d6a>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 2630e0cf160, executio...rue silent=False shell_futures=True> result=None>)\n   2896             raise ValueError(\"Interactivity was %r\" % interactivity)\n   2897         try:\n   2898             for i, node in enumerate(to_run_exec):\n   2899                 mod = ast.Module([node])\n   2900                 code = compiler(mod, cell_name, \"exec\")\n-> 2901                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000002630D774300, file \"<ipython-input-61-9bd2d6d04d6a>\", line 4>\n        result = <ExecutionResult object at 2630e0cf160, executio...rue silent=False shell_futures=True> result=None>\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000002630D774300, file \"<ipython-input-61-9bd2d6d04d6a>\", line 4>, result=<ExecutionResult object at 2630e0cf160, executio...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000002630D774300, file \"<ipython-input-61-9bd2d6d04d6a>\", line 4>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().run_line_magic('matplotlib', 'inli...trix\\nstop_words = set(stopwords.words('english'))\", r'allFiles = glob.glob(\"C:\\*.txt\")', 'print(allFiles)', \"frame = pd.DataFrame()\\nlist_ = []\\nfor file_ in a...3']\\n    list_.append(df)\\nframe = pd.concat(list_)\", 'print((frame))', 'tfidf__max_df: (0.25, 0.50, 0.75)\\ntfidf__ngram_range: ((1, 1), (1, 2), (1, 3))', \"data_x = frame[['title']].as_matrix()\\nprint(data...e[['conference_short']].as_matrix()\\nprint(data_y)\", 'stratified_split = StratifiedShuffleSplit(n_spli...].strip() for x in x_test.tolist()]\\nprint(y_test)', \"pipeline_NB = Pipeline([\\n    ('tfidf', TfidfVect...1, 3)],\\n    'clf_estimator_alpha': (1e-2, 1e-3)\\n}\", 'grid_search_tune = GridSearchCV(\\n    pipeline_NB...print(classification_report(y_test, predictions))', \"#KNN\\npipeline_KNN = Pipeline([\\n    ('tfidf', Tfi... 'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)]\\n}\", 'confusion_matrix(y_test, predictions, labels=[\"vldb\", \"icse\"])', \"#KNN\\npipeline_KNN = Pipeline([\\n    ('tfidf', Tfi...1, 3)],\\n    'clf_estimator_alpha': (1e-2, 1e-3)\\n}\", 'grid_search_tune = GridSearchCV(\\n    pipeline_KN...print(classification_report(y_test, predictions))', \"pipeline_tf = Pipeline([('tfidf', TfidfVectorize...'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\\n}\", \"#Naive's Bayes\\npipeline_NB = Pipeline([\\n    ('tf... 3)],\\n    'clf__estimator__alpha': (1e-2, 1e-3)\\n}\", '#SVM\\npipeline_SVM = Pipeline(\\n    [\\n    (\\'tfidf\\'...__estimator__class_weight\": [\\'balanced\\', None],\\n}', '#Logistic Regression\\npipeline_logistic = Pipelin...__estimator__class_weight\": [\\'balanced\\', None],\\n}', '#Naive\\'s Bayes\\npipeline_NB = Pipeline([\\n    (\\'tf...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KMeans': <class 'sklearn.cluster.k_means_.KMeans'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'ListedColormap': <class 'matplotlib.colors.ListedColormap'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().run_line_magic('matplotlib', 'inli...trix\\nstop_words = set(stopwords.words('english'))\", r'allFiles = glob.glob(\"C:\\*.txt\")', 'print(allFiles)', \"frame = pd.DataFrame()\\nlist_ = []\\nfor file_ in a...3']\\n    list_.append(df)\\nframe = pd.concat(list_)\", 'print((frame))', 'tfidf__max_df: (0.25, 0.50, 0.75)\\ntfidf__ngram_range: ((1, 1), (1, 2), (1, 3))', \"data_x = frame[['title']].as_matrix()\\nprint(data...e[['conference_short']].as_matrix()\\nprint(data_y)\", 'stratified_split = StratifiedShuffleSplit(n_spli...].strip() for x in x_test.tolist()]\\nprint(y_test)', \"pipeline_NB = Pipeline([\\n    ('tfidf', TfidfVect...1, 3)],\\n    'clf_estimator_alpha': (1e-2, 1e-3)\\n}\", 'grid_search_tune = GridSearchCV(\\n    pipeline_NB...print(classification_report(y_test, predictions))', \"#KNN\\npipeline_KNN = Pipeline([\\n    ('tfidf', Tfi... 'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)]\\n}\", 'confusion_matrix(y_test, predictions, labels=[\"vldb\", \"icse\"])', \"#KNN\\npipeline_KNN = Pipeline([\\n    ('tfidf', Tfi...1, 3)],\\n    'clf_estimator_alpha': (1e-2, 1e-3)\\n}\", 'grid_search_tune = GridSearchCV(\\n    pipeline_KN...print(classification_report(y_test, predictions))', \"pipeline_tf = Pipeline([('tfidf', TfidfVectorize...'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\\n}\", \"#Naive's Bayes\\npipeline_NB = Pipeline([\\n    ('tf... 3)],\\n    'clf__estimator__alpha': (1e-2, 1e-3)\\n}\", '#SVM\\npipeline_SVM = Pipeline(\\n    [\\n    (\\'tfidf\\'...__estimator__class_weight\": [\\'balanced\\', None],\\n}', '#Logistic Regression\\npipeline_logistic = Pipelin...__estimator__class_weight\": [\\'balanced\\', None],\\n}', '#Naive\\'s Bayes\\npipeline_NB = Pipeline([\\n    (\\'tf...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KMeans': <class 'sklearn.cluster.k_means_.KMeans'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'ListedColormap': <class 'matplotlib.colors.ListedColormap'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\<ipython-input-61-9bd2d6d04d6a> in <module>()\n      1 grid_search_tune = GridSearchCV(\n      2     pipeline_NB\n      3     , parameters_NB, cv=2, n_jobs=2, verbose=3)\n----> 4 grid_search_tune.fit(train_x, y_train)\n      5 \n      6 \n      7 print(\"Parameters:\")\n      8 print(grid_search_tune.best_estimator_.steps)\n      9 \n     10 # measuring performance on test set\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=2, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=3), X=['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...], y=array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object), groups=None, **fit_params={})\n    635                                   return_train_score=self.return_train_score,\n    636                                   return_n_test_samples=True,\n    637                                   return_times=True, return_parameters=False,\n    638                                   error_score=self.error_score)\n    639           for parameters, (train, test) in product(candidate_params,\n--> 640                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=2, random_state=None, shuffle=False)>\n        X = ['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...]\n        y = array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object)\n        groups = None\n    641 \n    642         # if one choose to see train score, \"out\" will contain train score info\n    643         if self.return_train_score:\n    644             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Nov 27 21:38:50 2018\nPID: 16784   Python 3.7.0: C:\\Users\\aayushi srivastava\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), ['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...], array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object), {'score': <function _passthrough_scorer>}, array([4818, 4819, 4820, ..., 9650, 9651, 9652]), array([   0,    1,    2, ..., 4842, 4843, 4847]), 3, {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), ['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...], array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object), {'score': <function _passthrough_scorer>}, array([4818, 4819, 4820, ..., 9650, 9651, 9652]), array([   0,    1,    2, ..., 4842, 4843, 4847]), 3, {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), X=['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...], y=array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object), scorer={'score': <function _passthrough_scorer>}, train=array([4818, 4819, 4820, ..., 9650, 9651, 9652]), test=array([   0,    1,    2, ..., 4842, 4843, 4847]), verbose=3, parameters={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...or=None, fit_prior=True),\n          n_jobs=1))])>\n        parameters = {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), **kwargs={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...or=None, fit_prior=True),\n          n_jobs=1))])>\n        kwargs = {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), attr='steps', **params={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...or=None, fit_prior=True),\n          n_jobs=1))])>\n        params = {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), **params={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'clf_estimator_alpha'\n        self = Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter clf_estimator_alpha for estimator Pipeline(memory=None,\n     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n ...assifier(estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n          n_jobs=1))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 444, in _fit_and_score\n    estimator.set_params(**parameters)\n  File \"C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 142, in set_params\n    self._set_params('steps', **kwargs)\n  File \"C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\", line 49, in _set_params\n    super(_BaseComposition, self).set_params(**params)\n  File \"C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 274, in set_params\n    (key, self))\nValueError: Invalid parameter clf_estimator_alpha for estimator Pipeline(memory=None,\n     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n ...assifier(estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n          n_jobs=1))]). Check the list of available parameters with `estimator.get_params().keys()`.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\multiprocessing\\pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Nov 27 21:38:50 2018\nPID: 16784   Python 3.7.0: C:\\Users\\aayushi srivastava\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), ['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...], array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object), {'score': <function _passthrough_scorer>}, array([4818, 4819, 4820, ..., 9650, 9651, 9652]), array([   0,    1,    2, ..., 4842, 4843, 4847]), 3, {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), ['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...], array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object), {'score': <function _passthrough_scorer>}, array([4818, 4819, 4820, ..., 9650, 9651, 9652]), array([   0,    1,    2, ..., 4842, 4843, 4847]), 3, {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), X=['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...], y=array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object), scorer={'score': <function _passthrough_scorer>}, train=array([4818, 4819, 4820, ..., 9650, 9651, 9652]), test=array([   0,    1,    2, ..., 4842, 4843, 4847]), verbose=3, parameters={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...or=None, fit_prior=True),\n          n_jobs=1))])>\n        parameters = {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), **kwargs={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...or=None, fit_prior=True),\n          n_jobs=1))])>\n        kwargs = {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), attr='steps', **params={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...or=None, fit_prior=True),\n          n_jobs=1))])>\n        params = {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), **params={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'clf_estimator_alpha'\n        self = Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter clf_estimator_alpha for estimator Pipeline(memory=None,\n     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n ...assifier(estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n          n_jobs=1))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    698\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 657\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nValueError                                         Tue Nov 27 21:38:50 2018\nPID: 16784   Python 3.7.0: C:\\Users\\aayushi srivastava\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), ['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...], array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object), {'score': <function _passthrough_scorer>}, array([4818, 4819, 4820, ..., 9650, 9651, 9652]), array([   0,    1,    2, ..., 4842, 4843, 4847]), 3, {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), ['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...], array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object), {'score': <function _passthrough_scorer>}, array([4818, 4819, 4820, ..., 9650, 9651, 9652]), array([   0,    1,    2, ..., 4842, 4843, 4847]), 3, {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), X=['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...], y=array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object), scorer={'score': <function _passthrough_scorer>}, train=array([4818, 4819, 4820, ..., 9650, 9651, 9652]), test=array([   0,    1,    2, ..., 4842, 4843, 4847]), verbose=3, parameters={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...or=None, fit_prior=True),\n          n_jobs=1))])>\n        parameters = {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), **kwargs={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...or=None, fit_prior=True),\n          n_jobs=1))])>\n        kwargs = {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), attr='steps', **params={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...or=None, fit_prior=True),\n          n_jobs=1))])>\n        params = {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), **params={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'clf_estimator_alpha'\n        self = Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter clf_estimator_alpha for estimator Pipeline(memory=None,\n     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n ...assifier(estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n          n_jobs=1))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJoblibValueError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-9bd2d6d04d6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mpipeline_NB\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     , parameters_NB, cv=2, n_jobs=2, verbose=3)\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgrid_search_tune\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    638\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    639\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 640\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    641\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    787\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 789\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    790\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 740\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibValueError\u001b[0m: JoblibValueError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\runpy.py in _run_code(code=<code object <module> at 0x00000263054A2F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-p...ges\\__pycache__\\ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\a...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), pkg_name='', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x00000263054A2F60, fil...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': r'C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-p...ges\\__pycache__\\ipykernel_launcher.cpython-37.pyc', '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': '', '__spec__': ModuleSpec(name='ipykernel_launcher', loader=<_f...nda3\\\\lib\\\\site-packages\\\\ipykernel_launcher.py'), 'app': <module 'ipykernel.kernelapp' from 'C:\\\\Users\\\\a...a3\\\\lib\\\\site-packages\\\\ipykernel\\\\kernelapp.py'>, ...}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    494         if self.poller is not None:\n    495             self.poller.start()\n    496         self.kernel.start()\n    497         self.io_loop = ioloop.IOLoop.current()\n    498         try:\n--> 499             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    500         except KeyboardInterrupt:\n    501             pass\n    502 \n    503 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    127         except (RuntimeError, AssertionError):\n    128             old_loop = None\n    129         try:\n    130             self._setup_logging()\n    131             asyncio.set_event_loop(self.asyncio_loop)\n--> 132             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Win...EventLoop running=True closed=False debug=False>>\n    133         finally:\n    134             asyncio.set_event_loop(old_loop)\n    135 \n    136     def stop(self):\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\asyncio\\base_events.py in run_forever(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n    518         sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    519                                finalizer=self._asyncgen_finalizer_hook)\n    520         try:\n    521             events._set_running_loop(self)\n    522             while True:\n--> 523                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_Windo...EventLoop running=True closed=False debug=False>>\n    524                 if self._stopping:\n    525                     break\n    526         finally:\n    527             self._stopping = False\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\asyncio\\base_events.py in _run_once(self=<_WindowsSelectorEventLoop running=True closed=False debug=False>)\n   1753                         logger.warning('Executing %s took %.3f seconds',\n   1754                                        _format_handle(handle), dt)\n   1755                 finally:\n   1756                     self._current_handle = None\n   1757             else:\n-> 1758                 handle._run()\n        handle._run = <bound method Handle._run of <Handle BaseAsyncIOLoop._handle_events(512, 1)>>\n   1759         handle = None  # Needed to break cycles when an exception occurs.\n   1760 \n   1761     def _set_coroutine_origin_tracking(self, enabled):\n   1762         if bool(enabled) == bool(self._coroutine_origin_tracking_enabled):\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\asyncio\\events.py in _run(self=<Handle BaseAsyncIOLoop._handle_events(512, 1)>)\n     83     def cancelled(self):\n     84         return self._cancelled\n     85 \n     86     def _run(self):\n     87         try:\n---> 88             self._context.run(self._callback, *self._args)\n        self._context.run = <built-in method run of Context object>\n        self._callback = <bound method BaseAsyncIOLoop._handle_events of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (512, 1)\n     89         except Exception as exc:\n     90             cb = format_helpers._format_callback_source(\n     91                 self._callback, self._args)\n     92             msg = f'Exception in callback {cb}'\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py in _handle_events(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, fd=512, events=1)\n    117             self.writers.remove(fd)\n    118         del self.handlers[fd]\n    119 \n    120     def _handle_events(self, fd, events):\n    121         fileobj, handler_func = self.handlers[fd]\n--> 122         handler_func(fileobj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fileobj = <zmq.sugar.socket.Socket object>\n        events = 1\n    123 \n    124     def start(self):\n    125         try:\n    126             old_loop = asyncio.get_event_loop()\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    295         # Fast path when there are no active contexts.\n    296         def null_wrapper(*args, **kwargs):\n    297             try:\n    298                 current_state = _state.contexts\n    299                 _state.contexts = cap_contexts[0]\n--> 300                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    301             finally:\n    302                 _state.contexts = current_state\n    303         null_wrapper._wrapped = True\n    304         return null_wrapper\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 28, 2, 38, 49, 932857, tzinfo=tzutc()), 'msg_id': '99c90725bb674a8b811a39cebaebfc3a', 'msg_type': 'execute_request', 'session': 'd1417ed41c9c43b6af31277b610f6eb2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '99c90725bb674a8b811a39cebaebfc3a', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warning(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'd1417ed41c9c43b6af31277b610f6eb2']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 28, 2, 38, 49, 932857, tzinfo=tzutc()), 'msg_id': '99c90725bb674a8b811a39cebaebfc3a', 'msg_type': 'execute_request', 'session': 'd1417ed41c9c43b6af31277b610f6eb2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '99c90725bb674a8b811a39cebaebfc3a', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'd1417ed41c9c43b6af31277b610f6eb2'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 11, 28, 2, 38, 49, 932857, tzinfo=tzutc()), 'msg_id': '99c90725bb674a8b811a39cebaebfc3a', 'msg_type': 'execute_request', 'session': 'd1417ed41c9c43b6af31277b610f6eb2', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': '99c90725bb674a8b811a39cebaebfc3a', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='grid_search_tune = GridSearchCV(\\n    pipeline_NB...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Expr object>, <_ast.Assign object>, <_ast.Assign object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-61-9bd2d6d04d6a>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 2630e0cf160, executio...rue silent=False shell_futures=True> result=None>)\n   2896             raise ValueError(\"Interactivity was %r\" % interactivity)\n   2897         try:\n   2898             for i, node in enumerate(to_run_exec):\n   2899                 mod = ast.Module([node])\n   2900                 code = compiler(mod, cell_name, \"exec\")\n-> 2901                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x000002630D774300, file \"<ipython-input-61-9bd2d6d04d6a>\", line 4>\n        result = <ExecutionResult object at 2630e0cf160, executio...rue silent=False shell_futures=True> result=None>\n   2902                     return True\n   2903 \n   2904             for i, node in enumerate(to_run_interactive):\n   2905                 mod = ast.Interactive([node])\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x000002630D774300, file \"<ipython-input-61-9bd2d6d04d6a>\", line 4>, result=<ExecutionResult object at 2630e0cf160, executio...rue silent=False shell_futures=True> result=None>)\n   2956         outflag = True  # happens in more places, so it's easier as default\n   2957         try:\n   2958             try:\n   2959                 self.hooks.pre_run_code_hook()\n   2960                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2961                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x000002630D774300, file \"<ipython-input-61-9bd2d6d04d6a>\", line 4>\n        self.user_global_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().run_line_magic('matplotlib', 'inli...trix\\nstop_words = set(stopwords.words('english'))\", r'allFiles = glob.glob(\"C:\\*.txt\")', 'print(allFiles)', \"frame = pd.DataFrame()\\nlist_ = []\\nfor file_ in a...3']\\n    list_.append(df)\\nframe = pd.concat(list_)\", 'print((frame))', 'tfidf__max_df: (0.25, 0.50, 0.75)\\ntfidf__ngram_range: ((1, 1), (1, 2), (1, 3))', \"data_x = frame[['title']].as_matrix()\\nprint(data...e[['conference_short']].as_matrix()\\nprint(data_y)\", 'stratified_split = StratifiedShuffleSplit(n_spli...].strip() for x in x_test.tolist()]\\nprint(y_test)', \"pipeline_NB = Pipeline([\\n    ('tfidf', TfidfVect...1, 3)],\\n    'clf_estimator_alpha': (1e-2, 1e-3)\\n}\", 'grid_search_tune = GridSearchCV(\\n    pipeline_NB...print(classification_report(y_test, predictions))', \"#KNN\\npipeline_KNN = Pipeline([\\n    ('tfidf', Tfi... 'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)]\\n}\", 'confusion_matrix(y_test, predictions, labels=[\"vldb\", \"icse\"])', \"#KNN\\npipeline_KNN = Pipeline([\\n    ('tfidf', Tfi...1, 3)],\\n    'clf_estimator_alpha': (1e-2, 1e-3)\\n}\", 'grid_search_tune = GridSearchCV(\\n    pipeline_KN...print(classification_report(y_test, predictions))', \"pipeline_tf = Pipeline([('tfidf', TfidfVectorize...'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\\n}\", \"#Naive's Bayes\\npipeline_NB = Pipeline([\\n    ('tf... 3)],\\n    'clf__estimator__alpha': (1e-2, 1e-3)\\n}\", '#SVM\\npipeline_SVM = Pipeline(\\n    [\\n    (\\'tfidf\\'...__estimator__class_weight\": [\\'balanced\\', None],\\n}', '#Logistic Regression\\npipeline_logistic = Pipelin...__estimator__class_weight\": [\\'balanced\\', None],\\n}', '#Naive\\'s Bayes\\npipeline_NB = Pipeline([\\n    (\\'tf...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KMeans': <class 'sklearn.cluster.k_means_.KMeans'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'ListedColormap': <class 'matplotlib.colors.ListedColormap'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, ...}\n        self.user_ns = {'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', \"get_ipython().run_line_magic('matplotlib', 'inli...trix\\nstop_words = set(stopwords.words('english'))\", r'allFiles = glob.glob(\"C:\\*.txt\")', 'print(allFiles)', \"frame = pd.DataFrame()\\nlist_ = []\\nfor file_ in a...3']\\n    list_.append(df)\\nframe = pd.concat(list_)\", 'print((frame))', 'tfidf__max_df: (0.25, 0.50, 0.75)\\ntfidf__ngram_range: ((1, 1), (1, 2), (1, 3))', \"data_x = frame[['title']].as_matrix()\\nprint(data...e[['conference_short']].as_matrix()\\nprint(data_y)\", 'stratified_split = StratifiedShuffleSplit(n_spli...].strip() for x in x_test.tolist()]\\nprint(y_test)', \"pipeline_NB = Pipeline([\\n    ('tfidf', TfidfVect...1, 3)],\\n    'clf_estimator_alpha': (1e-2, 1e-3)\\n}\", 'grid_search_tune = GridSearchCV(\\n    pipeline_NB...print(classification_report(y_test, predictions))', \"#KNN\\npipeline_KNN = Pipeline([\\n    ('tfidf', Tfi... 'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)]\\n}\", 'confusion_matrix(y_test, predictions, labels=[\"vldb\", \"icse\"])', \"#KNN\\npipeline_KNN = Pipeline([\\n    ('tfidf', Tfi...1, 3)],\\n    'clf_estimator_alpha': (1e-2, 1e-3)\\n}\", 'grid_search_tune = GridSearchCV(\\n    pipeline_KN...print(classification_report(y_test, predictions))', \"pipeline_tf = Pipeline([('tfidf', TfidfVectorize...'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\\n}\", \"#Naive's Bayes\\npipeline_NB = Pipeline([\\n    ('tf... 3)],\\n    'clf__estimator__alpha': (1e-2, 1e-3)\\n}\", '#SVM\\npipeline_SVM = Pipeline(\\n    [\\n    (\\'tfidf\\'...__estimator__class_weight\": [\\'balanced\\', None],\\n}', '#Logistic Regression\\npipeline_logistic = Pipelin...__estimator__class_weight\": [\\'balanced\\', None],\\n}', '#Naive\\'s Bayes\\npipeline_NB = Pipeline([\\n    (\\'tf...rix(y_test, predictions, labels=[\"vldb\", \"icse\"])', ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KMeans': <class 'sklearn.cluster.k_means_.KMeans'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, 'LinearSVC': <class 'sklearn.svm.classes.LinearSVC'>, 'ListedColormap': <class 'matplotlib.colors.ListedColormap'>, 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'MultinomialNB': <class 'sklearn.naive_bayes.MultinomialNB'>, 'OneVsRestClassifier': <class 'sklearn.multiclass.OneVsRestClassifier'>, ...}\n   2962             finally:\n   2963                 # Reset our crash handler in place\n   2964                 sys.excepthook = old_excepthook\n   2965         except SystemExit as e:\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\<ipython-input-61-9bd2d6d04d6a> in <module>()\n      1 grid_search_tune = GridSearchCV(\n      2     pipeline_NB\n      3     , parameters_NB, cv=2, n_jobs=2, verbose=3)\n----> 4 grid_search_tune.fit(train_x, y_train)\n      5 \n      6 \n      7 print(\"Parameters:\")\n      8 print(grid_search_tune.best_estimator_.steps)\n      9 \n     10 # measuring performance on test set\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py in fit(self=GridSearchCV(cv=2, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=3), X=['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...], y=array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object), groups=None, **fit_params={})\n    635                                   return_train_score=self.return_train_score,\n    636                                   return_n_test_samples=True,\n    637                                   return_times=True, return_parameters=False,\n    638                                   error_score=self.error_score)\n    639           for parameters, (train, test) in product(candidate_params,\n--> 640                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=2, random_state=None, shuffle=False)>\n        X = ['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...]\n        y = array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object)\n        groups = None\n    641 \n    642         # if one choose to see train score, \"out\" will contain train score info\n    643         if self.return_train_score:\n    644             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nValueError                                         Tue Nov 27 21:38:50 2018\nPID: 16784   Python 3.7.0: C:\\Users\\aayushi srivastava\\Anaconda3\\python.exe\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), ['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...], array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object), {'score': <function _passthrough_scorer>}, array([4818, 4819, 4820, ..., 9650, 9651, 9652]), array([   0,    1,    2, ..., 4842, 4843, 4847]), 3, {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}), {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), ['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...], array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object), {'score': <function _passthrough_scorer>}, array([4818, 4819, 4820, ..., 9650, 9651, 9652]), array([   0,    1,    2, ..., 4842, 4843, 4847]), 3, {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n        kwargs = {'error_score': 'raise', 'fit_params': {}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), X=['Failure mechanism observed through static latchup simulation', 'A Processing Interface for Multiple External Schema Access to a Data Base Management System', 'Parallel Query Scheduling and Optimization with Time- and Space-Shared Resources', 'An adaptive threshold segmentation method based on BP neural network for paper defect detection', 'Evaluation of Main Memory Join Algorithms for Joins with Set Comparison Join Predicates', 'Departures from optimality: understanding human ...rmation foraging in assisted requirements tracing', 'An adaptive distributed query processing grid service', 'A decision support system for classification and recognition of earthquakes and explosions', 'Software product lines (workshop session): economics, architectures, and applications', 'Exploring the internal state of user interfaces ...uter vision techniques with grammatical inference', 'Detection of Potential Interference Among Aspects Using Graphical Notation', 'Daily build and feature development in large distributed projects', 'A light-weight publisher-subscriber middleware f...nfiguration in networks of embedded smart cameras', 'Making software knowledgeable', 'Project estimation using Screenflow Engineering', 'Spatio-Temporal Retrieval with RasDaMan', 'An incremental flow- and context-sensitive pointer aliasing analysis', 'Decentralised process modelling in a multi-perspective development environment', 'Design of a micromechanical system utilizing hydrogel force for controlling a microvalve', 'Spatial keyword query processing: an experimental evaluation', ...], y=array([['icse'],\n       ['vldb'],\n       ['vldb'...\n       ['icse'],\n       ['icse']], dtype=object), scorer={'score': <function _passthrough_scorer>}, train=array([4818, 4819, 4820, ..., 9650, 9651, 9652]), test=array([   0,    1,    2, ..., 4842, 4843, 4847]), verbose=3, parameters={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}, fit_params={}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    439                       for k, v in fit_params.items()])\n    440 \n    441     test_scores = {}\n    442     train_scores = {}\n    443     if parameters is not None:\n--> 444         estimator.set_params(**parameters)\n        estimator.set_params = <bound method Pipeline.set_params of Pipeline(me...or=None, fit_prior=True),\n          n_jobs=1))])>\n        parameters = {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}\n    445 \n    446     start_time = time.time()\n    447 \n    448     X_train, y_train = _safe_split(estimator, X, y, train)\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py in set_params(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), **kwargs={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n    137 \n    138         Returns\n    139         -------\n    140         self\n    141         \"\"\"\n--> 142         self._set_params('steps', **kwargs)\n        self._set_params = <bound method _BaseComposition._set_params of Pi...or=None, fit_prior=True),\n          n_jobs=1))])>\n        kwargs = {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}\n    143         return self\n    144 \n    145     def _validate_steps(self):\n    146         names, estimators = zip(*self.steps)\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\metaestimators.py in _set_params(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), attr='steps', **params={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n     44         names, _ = zip(*getattr(self, attr))\n     45         for name in list(six.iterkeys(params)):\n     46             if '__' not in name and name in names:\n     47                 self._replace_estimator(attr, name, params.pop(name))\n     48         # 3. Step parameters and other initilisation arguments\n---> 49         super(_BaseComposition, self).set_params(**params)\n        self.set_params = <bound method Pipeline.set_params of Pipeline(me...or=None, fit_prior=True),\n          n_jobs=1))])>\n        params = {'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)}\n     50         return self\n     51 \n     52     def _replace_estimator(self, attr, name, new_val):\n     53         # assumes `name` is a valid estimator name\n\n...........................................................................\nC:\\Users\\aayushi srivastava\\Anaconda3\\lib\\site-packages\\sklearn\\base.py in set_params(self=Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))]), **params={'clf_estimator_alpha': 0.01, 'tfidf__max_df': 0.25, 'tfidf__ngram_range': (1, 1)})\n    269             key, delim, sub_key = key.partition('__')\n    270             if key not in valid_params:\n    271                 raise ValueError('Invalid parameter %s for estimator %s. '\n    272                                  'Check the list of available parameters '\n    273                                  'with `estimator.get_params().keys()`.' %\n--> 274                                  (key, self))\n        key = 'clf_estimator_alpha'\n        self = Pipeline(memory=None,\n     steps=[('tfidf', Tfid...ior=None, fit_prior=True),\n          n_jobs=1))])\n    275 \n    276             if delim:\n    277                 nested_params[key][sub_key] = value\n    278             else:\n\nValueError: Invalid parameter clf_estimator_alpha for estimator Pipeline(memory=None,\n     steps=[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_idf=True,\n ...assifier(estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n          n_jobs=1))]). Check the list of available parameters with `estimator.get_params().keys()`.\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline_NB\n",
    "    , parameters_NB, cv=2, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(train_x, y_train)\n",
    "\n",
    "\n",
    "print(\"Parameters:\")\n",
    "print(grid_search_tune.best_estimator_.steps)\n",
    "\n",
    "# measuring performance on test set\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(test_x)\n",
    "\n",
    "print(classification_report(y_test, predictions))\n",
    "\n",
    "confusion_matrix(y_test, predictions, labels=[\"vldb\", \"icse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_KNN = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', OneVsRestClassifier(KNeighborsClassifier(\n",
    "        n_neighbors=5))),\n",
    "])\n",
    "parameters_KNN = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 9 candidates, totalling 18 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  18 out of  18 | elapsed:   18.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters set:\n",
      "[('tfidf', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.25, max_features=None, min_df=1,\n",
      "        ngram_range=(1, 3), norm='l2', preprocessor=None, smooth_idf=True,\n",
      "        stop_words={'than', 'just', 'yourselves', \"haven't\", 'there', 'm', 'have', 'or', 'they', 'yourself', 'does', \"wasn't\", \"mightn't\", 'be', 'but', 'no', 'here', 'until', 'against', 'was', 'by', 'when', \"it's\", 'wasn', 'your', 'are', 'mightn', 'hers', 'such', 'only', 'too', 'he', \"shouldn't\", 'being', '... 'its', 'other', 'up', 'our', 'in', 'why', \"weren't\", 'wouldn', 'ain', 'am', 'most', 'so', 'couldn'},\n",
      "        strip_accents=None, sublinear_tf=False,\n",
      "        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b', tokenizer=None, use_idf=True,\n",
      "        vocabulary=None)), ('clf', OneVsRestClassifier(estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform'),\n",
      "          n_jobs=1))]\n",
      "Applying best classifier on test data:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       icse       0.93      0.93      0.93      3328\n",
      "       vldb       0.84      0.84      0.84      1427\n",
      "\n",
      "avg / total       0.91      0.91      0.91      4755\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_search_tune = GridSearchCV(\n",
    "    pipeline_KNN\n",
    "    , parameters_KNN, cv=2, n_jobs=2, verbose=3)\n",
    "grid_search_tune.fit(train_x, y_train)\n",
    "\n",
    "\n",
    "print(\"Best parameters set:\")\n",
    "print(grid_search_tune.best_estimator_.steps)\n",
    "\n",
    "# measuring performance on test set\n",
    "print(\"Applying best classifier on test data:\")\n",
    "best_clf = grid_search_tune.best_estimator_\n",
    "predictions = best_clf.predict(test_x)\n",
    "confusion_matrix(y_test, predictions, labels=[\"vldb\", \"icse\"])\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1156,  271],\n",
       "       [ 221, 3107]], dtype=int64)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_tf = Pipeline([('tfidf', TfidfVectorizer(stop_words=stop_words))])\n",
    "parameters_logistic = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.02997328 -0.01464728]\n",
      " [-0.02899673 -0.01614608]\n",
      " [ 0.12200902 -0.01192484]\n",
      " ...\n",
      " [-0.04155103 -0.01116812]\n",
      " [ 0.14905788 -0.01625076]\n",
      " [-0.04324405 -0.01010824]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD8CAYAAACfF6SlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3X1wHPWZJ/DvM2PJlmRj+Y0XSbZlB4jhXARiYUzCJuyFUPZuxejOJGv2UkfqskvtXuWu6ojIEkLYhLiSDWiT26qj7kKxe5dks5gAWWESfElIQl3IYrB09hGDMRi/6cXY+EXC6F2j5/7oaU1PT/d090zPTM/091NFWdPqmemW0NM9z+/5PT9RVRARUbwkKn0ARERUfgz+REQxxOBPRBRDDP5ERDHE4E9EFEMM/kREMcTgT0QUQwz+REQxxOBPRBRD8yp9AG6WL1+u7e3tlT4MIqKq0tfXd0ZVV3jtF9ng397ejt7e3kofBhFRVRGR4372Y9qHiCiGGPyJiGKIwZ+IKIYY/ImIYojBn4gohhj8iYhiiMGfiCiGGPyJiGIospO8iCpq9H3gwgiQSgHJJLBoMdC0sNJHRRQaBn8iu9H3gZHzgKrxOJUyHgO8AFDNYNqHyO7CSCbwm1SN7UQ1gsGfyC6VCradqAox+BPZJZPBthNVoVCCv4hsFpFDInJYRO512eczIvK6iLwmIv8UxvsSlcSixYBI9jYRYztRjSh6wFdEkgAeAfBJAAMA9orILlV93bLPFQC+DOCjqnpeRC4u9n2JSsYc1GW1D9WwMKp9NgI4rKpHAEBEdgK4DcDrln3+HMAjqnoeAFT1dAjvS1Q6TQsZ7KmmhZH2aQXQb3k8kN5mdSWAK0XkdyKyR0Q2O72QiNwlIr0i0vvuu++GcGhEROQkjOAvDttsdXKYB+AKADcDuAPAYyLSnPMk1UdVtUNVO1as8FyFjIiIChRG8B8AsNLyuA3AkMM+z6jqtKoeBXAIxsWAiIgqIIzgvxfAFSKyRkTqAWwHsMu2Tw+APwQAEVkOIw10JIT3JiKiAhQd/FV1BsAXAPwcwEEAP1bV10TkQRHZmt7t5wDOisjrAH4D4B5VPVvsexMRUWFE7dPYI6Kjo0N7e3srfRhERFVFRPpUtcNrP87wJSKKIQZ/IqIYYvAnIoohBn8iohhi8CciiiEGfyKiGGLwJyKKIQZ/IqIYYvAnIoqhMPr5E1Gx+vqA3buB4WGguRnYsgXYsKHSR0U1jMGfqNL6+oCnngKmp43Hw8PGY4AXACoZpn2IKm337kzgN01PG9uJSoTBn6jShoeDbScKAYM/UaU15yxql387UQgY/IkqbcsWoK4ue1tdnbGdqEQ44EtUaeagLqt9qIwY/ImiYMMGBnsqK6Z9iIhiiMGfiCiGGPyJiGKIwZ+IKIbiOeA7+j5wYQRIpYBkEli0GGhaWOmjIiIqm/gF/9H3gZHzgKrxOJUyHgO8ABBRbMQv7XNhJBP4TarGdiKimIhf8E+lgm0nIqpB8Qv+yWSw7URENSh+Of9Fi7Nz/gAgYmyn/DhQTlQz4hf8zWDFIBYMB8qJakr8gj9gBCsGrGDyDZTzZ0lUdeIZ/E1MY/jHgXKimhK/AV+TmcYwg5eZxhh9v7LHFVUcKCeqKfG983dLY4ycN+7++akgGwfKiWpK/IK/Nag7UQXOnQUmxji4acWBcqKaEq/gb69YcTM+mruNg5scKCeqIaHk/EVks4gcEpHDInJvnv1uFxEVkY4w3jcwp1RPEBzcJKIaUXTwF5EkgEcAbAFwNYA7RORqh/0WAfjPAF4u9j0LVmzw5uAmEdWIMO78NwI4rKpHVHUKwE4Atzns9w0ADwGYCOE9C1NM8ObgJhHVkDBy/q0A+i2PBwDcYN1BRK4DsFJVfyoiXSG8Z2GcKlb8EAEWL2G+m7z19QG7dwPDw0BzM7BlCxdmp0gKI/iLw7a56CoiCQDfBfA5zxcSuQvAXQCwatWqEA7Nxl6x4lciwcBP3vr6gKeeAqanjcfDw8ZjgBcAipww0j4DAFZaHrcBGLI8XgRgPYAXROQYgE0AdjkN+qrqo6raoaodK1asCOHQHDQtBC5tBVpXAc1L/T0nlQLeGeQEMMpv9+5M4DdNTxvbiSImjOC/F8AVIrJGROoBbAewy/ymqo6o6nJVbVfVdgB7AGxV1d4Q3rs4TQsB8fkj4Axg8jI8HGw7UQUVnfZR1RkR+QKAnwNIAvgHVX1NRB4E0Kuqu/K/QoXpbIB9LTOAqTqUMwff3Owc6JubS/N+REUIZZKXqj4H4Dnbtgdc9r05jPcM5NzZ7IlbDU3A0mWFvZaqcfdf7AWA7SNKr9w5+C1bst8PAOrqjO1EEVP7jd3sgR8wHp87W3gKp9j1ftlUrjzKnYPfsAG4/fbMnX5zs/GYg70UQbXf3sGpVYO5fWLM/XmScE8JFTtZjL3xy6MSOfgNGxjsqSrUfvDPx63eXwRY3AyMDDtfAMSpujUA9sbPL6yUGHPwRK5qP+1TiAWN6clgLnf+ZufPQrE3vrswU2Jbthg5dyvm4IkA1HrwH32/sLv08VF/nT8LzdEvWpx7XGwfYciXEguKOXgiV7Wb9vFq39zQ5D4e4FehOXr2xncXdkqMOXgiR7Ub/L3aN+cb7PWrmBy9W298a75bEgDUOI+4XCCSSeefqz0lxlJZoqLUbtrHKzAX09ffFHaO/txZYPhc5th1Nnc1sVovB/WTEmOpLFHRajf4l3rwNOwc/ej73mmoQnPf1aRpodFB1fz9JZO5HVXDHBcgiqnaDf5Od5BhcQpIxfIbuOJQDtq00Pj9mSmgCyPZd/UslSUqWu0Gf/sdZJhm1UjPhNnp02/gikM5qFdah6WyREWr3QFfIHtQ1TpAWCyz/j+VMi4Cw+eMwdnFzYV9GvB7AYlLOajXDGinRXni8rMhCkltB38r80LgVQJaKJ01LgKTk8DURLAqlJHz3q8fp4qWfGmddwaNn8PiJdVV7cMVvihi4hP8TWaAcGvdUCzroK2ZrrC+r5N8F6LWEqxoFnVu5Z5A5me6eImxKE814ApfFEG1m/P3ZAu4IkBdfQnehlUogXkN1lfbz5QrfFEExe/OH3DPKU9Pleb9WIUSjJ+1lqvpZ8oVviiC4nnnX+7AwSqU4My1lmuhssetiyi7i1IFxTP4lzNwsAqlOLXQBI/dRSmC4pn2cSoVLIVqqEKJulpogmcO6rLahyIknsHfT045DH6rUfw2M4srs0y3kHLJqJRYsrsoRUw80z5AJqdcKkECdy2kNkrNLJc0B0nNcsm+vmDPefxx4Ktfzf88ohiIb/A3laL/T9DA7aeZWdwVUi7p9BwAGB/3vnAQ1bh4pn2yCHJq/otRaE7arb8/GQopl8z3PfPCwVQMxVQ8g//pd8Kv6RcBWlYW9lwuTOKtkMXY3Z5jYp09xVj80j6lCPxA4ZVDXJjEn0LKJZ2eY8U6e4qx2r/zt99Vl6q6p9DKnOFzudusHSwrKUqfSAoplzS/98wzwJht2U7W2VPM1Xbwt3fwLGVZZyoFDJ4wvvYbKM+dzf96YSkkiDv97Pw0qSsFe7nmHXf4z9WbJZZRKfkkiojaDv5ei7iXit9AmW/ZxrBq/AsN4l499cslrI6YrLMnylLbwb+Szb+KDZRh1fgXGsSj0lAtX4kng3l08ZNW5NV28C9ljt+PYt47rLvrQoN4VGYdsyNm9eH6BVWhtqt9SrmIux9egbKhKdj2MI/B69iiMuuYHTGrD9cvqAq1HfydZs6W82LgFSiXLssN9A1NxnYvo+8bSxoOnsi/kHyQIG59zQsjwILGys86ZkfM6sNPa1WhttM+QO7M2VKt4RuEvfqmeWmwoBpkENdvV0yn15wYq3ybCadyzXm1/79tVStkQh6VXW3f+TsxPw2Ug9NSg2FM6so3iOvEbGLXvNR4PHwu99NC0NcsN2sagb15oo2f1qpCPG+hzDtZpwlWYUqlcu/yZ7X4EspCBnG9Pi1EpbrHCSt+qgvXL6gKoQR/EdkM4O8AJAE8pqp/Y/v+3QD+DMAMgHcB/AdVPR7GexesaWHp0z+S8D/JLEiQLaQSx6vkMyrVPU6YQ64+nFcReUWnfUQkCeARAFsAXA3gDhG52rbbPgAdqnoNgKcAPFTs+4ai5Okfh7t8N2H2/3caDPa6s49KdY8TVvwQhS6MnP9GAIdV9YiqTgHYCeA26w6q+htVNZur7AHQFsL7Fq9pYbhllXZ+A3+Y/f/dxhQkz6969P1orynAHDJR6MJI+7QC6Lc8HgBwQ579Pw8gOgW/8+fnb7NQamH3/3dL7+SrcB0Zzjy3Uk3c8s0IZQ6ZKHRhBH+nsOJ4yysinwXQAeDjLt+/C8BdALBq1aoQDs2DeZdcKQ1NwNSEMfB8YSScgOuW3sn3KURnK9vEzc+MUOaQiUIVRtpnAIB1FZM2AEP2nUTkFgBfAbBVVSedXkhVH1XVDlXtWLFiRQiH5qHUjd9E8qeVxkfD7+Nf6IzeSpZ5ckYoUdmFcee/F8AVIrIGwCCA7QD+1LqDiFwH4HsANqvq6RDeMxylLmNUNWbrDvpMK4XRNXPR4twqJnNMIWh1U5CfTzGNvFjNQ3FXgUZ4RQd/VZ0RkS8A+DmMUs9/UNXXRORBAL2qugvAwwAWAnhSjIqSE6q6tdj3Llq5Gr8FeZ9ij8drRm+QuQ1+K5BqoZEXu1BSpVTo7yeUOn9VfQ7Ac7ZtD1i+viWM9wldIXfDpX6ffFU5frkNBjctBCYn/Q1wB6lAqvZJWGH98T39NLBnT3qAXYBNm4Bt28I/XqotFfr7iecMX5P9LrkU3hk0XlsSxtC4qscngZAvRNYZxiL+LkBBq32KTdu4HVe5mvCF8cf39NPASy9lHqtmHvMCQPlUKO0Z7+APZO6SzSAdNvM1ddYIZmYTN3PJR7swP4XYWzr4ee3WAqqsim3ktWlTduC0bi+HfH98O3Y4p4LsaaIRl8HxPXsY/Cm/CjXCY/A31S8ofb2/n3YKIpkLkXkHDhRWgx+0mqnQVg5btmSnTYBgk7DM4FiplInbHx+Q2T48DDz+uPFfYyMwMQHMzmbv46SS3WOpOhT791OgeAd/a0qkXKztFJzGAVSzyz/tA7RBavCDnFcxrRzCmIS1bVvl7pCd/vjyMVtL+1HJxYSoOlRoEmP8gn+ZA35KFQLg9PQ0+icncP2iizLtFACHjp+z3i/qtyTUb45fpPhWDtU8Ccv+xxemcqWuoogVVP5V4O8nXsG/Agu5JNN3fpfW12NxMom9F97D9ZJwXszFbRzAidPF69zZYKmrQto4eP1BV/Mf/PtFTrCz8pu6quafVz61UP5b4+IV/Es9o9dDQzKJlfMXGHf3Zuy2pnGCzAew5+eDBv6gq4cB3n/Q5fyD7+sDenqMhV0AIw9/222FvY953DMz4R3f9u3ex1LLAbLay39jIF7BPwILk1xs704JGBekkfPI333Npn5B9sBw0HMrJMXj9Qddrj/4vj7giScyA66AkYf/8Y+Nr4N+EnE6bi9eP3M/51zLAZKztiMvXss4+qhmGQvhAqF5Pl2cdgsy6jPfb5oYyx4YDqLQQUg/FTFBnleo3buzA78plcruB2TeWVuPz2n5x0KOb+PG/KV4w8Pey0x6lZhW8zKVXIMh8uIV/J0WLLHoOXsGf91/LOcCMFNAqmjvhfdyts2qon9yIvBrOSomfaWau9iLH15/0OX6g88XrM3v9fUBO3f6axhXyPEdPOhdiue1zrDXxSPf8/v6jAtEV1c0LxRcgyHy4pX28ZjR2z3Uj8HpKUyp4oG21Vg6z/jxvJ9KoXme/x+ViGB9U243TwGMah+fVBXicLFy2x6IvZso4J0K8qpHLqZeOcjAZ766fBEjIOZjf+6WLUb9fhDDw8bxHTvmPEEN8E7heJWYuj3faazg8ceNYwm7XLbQAWmuwRB58Qr+QHbfG9us3qHpqbmvGxKJuQAbJPBnnp+bYnIN2JJwTPmcT81ggSTQaElXjaVSmNBZLJ3nMHZQKFVjPsHwufwVQF5/0IX+wQcd+NyyJTfnbz0XL42NuecVNPibd+3btgHt7e7Pz/cpxU+JqdN2tzGKl14yjiWsAFvsgHQ1l//GQPyCv5VtolVLXT0Gp6dwT8vKrIBbMmZ9PeDYhvnr/cYa9/e0rERLfT2Gpqbw8JCxaNrfrbnc/3skEv4Hhr0+CXj9QRfyBx904NPcZq32CWJiwghs1td2+zTR0GBUAeX7NGMOdhcyRd/8eZltJOzMTzLWC2m+C0qYg8W1PCBNMQ/+tjRQV9tq3Hf8bbTU14fy8jOq+Om5s+hcttz4I17QaKzc5damwdbC4WfD55BSxa7zZ7Net3PpMv8HYV5cgkxsC2NdgSAKGSi2X2S8Uj1Ws7PGnfru3ZmA6vY7b20Frr/ee27D1FTuc4PkuN1SQOYNgfWu2087ijCwYqemxTv4A1lpoM7WVUDzEpyensalIVwAkgDuO3HUeO1rPuz7OEzbV63Bj44fydn1gZVrnF/DfpdvtmuwfaroOXsG3UP9GJqeQktdPbpaVhoXKKtylsV6Nbbq6wOeeSbTVqGhAejsLP7u09qvx83bbwN/8Rfu7+VUdhr0GM28ule5qXnXnW+Mork5O09fV2d8cimkZ1KFGo5ReTD423S2rQZODgKzxQe/wakpjOssHhrq9w7+DnZcYwSOnSeOIqWKpAi2r1qDJW4pKVXg0tbsbe8M5gT++04cxXh6jGFweipzgbJeAIpJewUdJMw3UNzXZ9TvWy9G4+NGwDWVcrlHrzGEnh7nsQfAOGd7q+d584xzGx83LhCplPOnBjf5BpoTCeCqq7J/ltafadA20xVqOEblweBvN/p+KIF/LJWay8+fnJ5Cz8Bx48IS0I5rNsxdBOa4tZ92Cti2/bqH+ucCv2lcZ9E91J8J/kGbvFmDvVPHS7dBQvsdqtmLSATo6DD22bnTOQDPzhqB156PD5tI9nE2NBjbxsaMC5vbmMP4eG7gB4zjNWcSFzJeYd51t7cDr7yS/fsVAfbv9/55+G0zzYqdmsbgbxfCouWqii+fOJqVq3+l/zg6580L3pbZSb51eu1sg7zWiiarue1Bjs2ejgGcO146DRLa0yVOd6huJZSmQoJnUCtWZN/9Wt/TK/e9Z0+4x5JMZu66d+/OvQFIpfz9TILMEWHFTs2K1yQvP0LIdQ9OTeUM0r4wch49p09l3mPkvP/JVXZNC42BXPNOP5l078ppm9jWUuc8lqEAbjr4e/TMzHgH/r4+4IEHjLyz3/bG1kBpTsByS5dEyenThX2yaGwMv49UfX0mEBcz6Mo20wTe+ecqclF3VcVjp04CSK/amN5+0p5bL7aixm2dXgA9A8fR/cYBDI2PoaWhEV1rLkdn08KsiqZxh8A7OD6G+141Zoq6pqjstd9+NTS4lzPWoiA9//2y3tW7DcY2Nhq/m3y/nzi3maY5vPO32Tszg9ki7thEBF9b1Y7Wuvqc1XjN3LpJw+wimdYzcBz3vdqHwfExKNIB/dBrxh196yp0rr8W3/xQB1obGh2fP55KofuNA+5vUEgTNMAIXHEJ/KVirbJxa59w223A7bdn9jXHUgDj3xtv5LKSBIB3/ll6Bo6ja/9ezKqipa4e323/QKB2DFaeufX01//91T68cPqdzF36uvUFDQybut84gHHbJxczoJuv29m2Gp1tq7H22Scdl4sfGs9z18oAXjlmwzdz0PXYseylLzs6cmdbE7lg8E8z75hT6bv+wekp3Hn4EP7+A1di46KL5j4ijc3O4uHBfvzgzCn3GnlkZgs7bQeMaqCHBvvx7PmzcwHYV9rFg1vgztqeXs3M9RjNTwX2ks2rriromChEZvXUsWNAb29mXEHVeBy0vUOtLiZDnhj805zumD/ZvAQfalo4txpXz9kz+KsTRzBluUA41sgD+GJLG/7qxFFMW1JI80XwxZY2DExO4uGh/pxBYSD3Lj2oloZGDDpcAOYCumU1s66WlVk1/4Cx4EzXuvW5ZYrDw97VN1Qe09OZO377drdGcE4BPkqLyfAiVHYM/mlOd8wfamzCra+/OjcTdmx2di7wm3Jq5NP+zbIVOD8zg29YlmacVMXdDjN2/RyLX13r1uO+V/uyLmRzAR3IWs3MPOa52b5m2unUGQb6cpk/H5icDP48t3EpMzVk/bTW2+sc4KPSuydKF6EYYfBPc7pj3jF4IpOSccnhA875/VlV7PBYk9daDWQ/lmLMTyTmgv+Suno8sP7azCcJ26ebzmXLMxeu1lWZMkwqj0ICvxfr4jVOF3EzwEeld09ULkIxw+Cf1rVuPe7e90pWMPZb89OYSGAslUJjMpnVN2dBIpFTUplIv675vaTI3DgDYLtLt8gp30zv8/UD+zCc/sNxuphM2GcrJ5PAL54HXv19Ztu8ecCttwDvvGu0UqjgOsfkQyI9AlXMPAnzk0EUevdE5SIUM7EK/m4BtPuNA455cr9GZ2dx6+uv4uaLmvGTc2fmcuhOtfTmFvN7KVU0JudhPDXjWu1jDkabd/OD42P44r5XYH91p5BtH0Po+e2L6G5IYuhjG9EyOYWuI0bpaffZd7DzV79GWwTWOY6lujp/JbTNzUYvoGLnEZh59Sj07onKRShmYhP8nQLol/b3AtCsQdlCDU5P4UdnTxf03PHUDI586tOu33cajPZzz9cyMYkn9r+O7jUrAaR/BnWK8eR8AMCGkQu4/r0LuGxyCh3vXUDrZIAGYxSu22/PpGLMHkd2jY3A/fcHa1/txAzwUendE5WLUMzEJvg7BdDpIAuml5ACWPvsk653/oUOAJ+cX4+2ySl854230fPtb+HbH1iF8XpjYtDWU2fwrTePojH9CaRtcgqzMFJHVGZmGuf++41/3YK7ebcfdOGZjg5jzWG31dcqnVePykUoZmIT/IupoCkHczbu3fteQe+5M+hYunwuRZWwjQv4ddO5Ydx0w7UYnJ/u52Pp6XLP0f65wG8yxyN4ASiz2dnswU2vNIjbnXJnp/F1NQbRKFyEYiY2wd+t/j1qFMCPjh/Bj08cm/tkUkjgr5udxd7mizDh0pe/hSmeaLEGe680iN+1lInyiE3wd6p/rxPjXjeMnH/YCk5JqaJ1cgpjiQTO17sv8j6UTgnZjSYSaJqd5d1/uVkHN/2kQfzcKT/9dHb7hyCreFHNi03wN/PoTtU+9hLParb19FlsHzqFlZNTaJmcwtD8etx6/TUYt30CeHjNyqycPwCMJRL4ypVr8M03j6KpGtotR4V1+cxCOA1uFpsGsc/QDrqKF9W82AR/INPQzIlT6WQ1+uXyJfjo+RHc+J6xVkDb5BS+8eZR3H/lmqwU0K5LjIld9xztn7tIPLxmJXZdvAyfHXwH118YrcjxV5RblY0X1cIDf2Oj0Ykz7FSN20IyflfxopoXSktnEdksIodE5LCI3Ovw/fki8kT6+y+LSHsY7xuWzrbVWOyyyEm1GU8mcf+Va3DdjR/G2o9txE03XItV4xP41qGjaJ2YhKiieWoaUMWuS5bjDzZdhw98/Ab8wabrsOuS5VgyPRPPwF9XV5nJbaVagtLtXCKY4qTKKDr4i0gSwCMAtgC4GsAdInK1bbfPAzivqpcD+C6Abxf7vmEbztO+odpMJxIYrq+DimDDyAWsHx1H57tn8eLL+/Gdg29jMpnIqvxpSKXw1beO4faTp/G9A4cqeOQV1NHhPqmolCtfmW0MwuZ2zFzFi9LCSPtsBHBYVY8AgIjsBHAbgNct+9wG4Gvpr58C8N9ERFSjcxtSLdVAQd1ztB8Nlvx999qV+OSZ83PpnlkASRj5/sY4D/QePOheZdPRUdpGd6VoY7Bpk/MxcxUvSgsj7dMKoN/yeCC9zXEfVZ0BMAJgWQjvHZqudevT1T+1YeupM/j9b/fmzNrtGH4P33rzKNomp5CAcfUXgBU+w8NG3t26ClZzs/G4vT2zXnIQzc3A5Zd7322Xoo3Btm3Gql1cxYtchHHn7/R/tv2O3s8+EJG7ANwFAKtWrSr+yAKLzAeRonS+8y4ePnTE8Zd7r8PkLkrr63OustmxI/iAbiKRaaec7wNuKdsYbNvGYE+uwgj+AwBWWh63ARhy2WdAROYBWAzgnP2FVPVRAI8CQEdHR1kjcfcbByJZ7x9UQyqFHW8dc/3FXjJVogHGWvD440b+/aqrstshFJKWmZ11XnAFyFQVVdMMXKo5YQT/vQCuEJE1AAYBbAfwp7Z9dgG4E8BLAG4H8Oso5fuB6Ld/8OsXe1/NW6Mf69SOH/Ye+MXk4/NV3HR3F/66RCEoOsmdzuF/AcDPARwE8GNVfU1EHhSRrend/h7AMhE5DOBuADnloJVW7AIqUcG2DRHilutnq2KKgFAmeanqcwCes217wPL1BAD3nsUR0LVuPb60f2/Vp35mEdLkDSqOWSVkXULR3M5WxRQBjBNpnW2rsXCeey+cavEvixfVyLB1lWlsNFoqA5kqoW3bnKuHmOOnCIhVewcv1T7Ra+upM+i4MMq8ftgS6Ulx+Sp+HnzQeTtbFVNE8c7fotrz/k49+ikEa9cCn/kMc/hUUxj8LbrWrUdDIZN5IoKDvSVy+DBw7BiwfbuRs7diDp+qFIO/RWfbanzzmg1ordJPAEPzC2tOp6iV6W0ltGeP+wxgpnWoCjHnb2Nt+7z22SerKig+1nYpvvb2iUofRm0yq8CYw6caweCfRzUF/oZUCte+F7wVM9fs9YndMKnGMO2Tx5Iq6fHfPDWNbx46is53z/ra3zokzJDmE7thUo2J/Z1/z8DxnKUdzbSPVsm9/3gy2DWcV/wCsEEa1ZhYB/+egeNZi7oPjo/hvlf7ABi5/5FSrbIUsslkEg+tXZl152/25ycba1M1awO3xkZgzKW/Uy2Xcvb15V8onmpWrIN/9xsH5gK/aTyVQvcbB9DZtrqqFng5Ob8eA/Pr59bjve+KdhxpasRQelvXkX7faaGa1dAAzJ+fadbW3p59R29f9Byo7VLOvr7sxWuGh43HAC8AMRDr4O/WydPc3rVuPf7LvlfKeUiFE8EfbLoOAFCXvuOfThgJnsEF89G17gP4ySXL8D8PvImqnclgXYykqyvYcxMysiq6AAAMx0lEQVQJYGoKGB83HjsFum3bjAtCXO6Ed+/OXUPYXFayVs+Z5sQ6+Lvd2ZszfTvbVuPBA/txPuptH1TRPD2Dkbp5aJmcwlgigfP12ZORUgnBmwubqjfwA0aTtPZ24+v6eiOY52NN8UxN5aZ1nAJdnEo53dpVl2JZSYqcWAf/rnXrs3L+ANCQTKJr3fq5xw+svxZ373slskO/AmDN+CSe7fv9XI5/7cc2Ou57uj5ijevMXLrfYDM9DTzzjPGv13hMXV32BCy3TwpxDnRuC9XU8hgHzYl14Yd1Rq8AaG1oxDev2TBX7WOqT0T3x6QAjjQuwJevXIOB+fWYBXCZS5uHi6O0ipeZS1++PNjzxsa8A39jY+7MW7eAFudAt2UL21XEWKzv/IHsGb12PQPH8aX9vZjW6FfN7LpkOXZdshxbT53BF4/04/4PrsG4rU9R68RENKqArLn0nTvDfW23Rcq3bMke3AQY6MyLY1zGOChL7IN/Psa6vtEP/KYPj7yHvYsX4dmLl2Hx9AxEFWPJ5Nzs1P+7+CL89eWr8fXDxyt3AWhuBu6/P/M46OI5Zh7fzcGDztsZ6JzFaYyDsjD451Ft6/q+trAJk+m7/eH6OjSkUvh3g6fwwvIlcyWfHz3/XmXv/O05Zq9gbqdq3LG7pX7y5fAZ6IjmRDeZHQHV1t9/0pbmGU8m8cLyJXjx5f048tI+vPjy/mjU+t9zj1FTDwRvm2B20mRvfaKiMPjn0bVuPeqkun9EQ/PrMwHTXGaw0lSNyVRPP23k52+80V/jNDNHv2EDe+sTFam6I1uJdbatxkPXdlRNgzcnLZNTmYD5jW8Ad9xh1MiHrbnZCOL2gJzPnj3Gv9u2AQ8/bByb2/PtvfPZW5+oKMz5e7BXA/UMHMfXD+zDcBX0/WlIpdA1b37uJKbdu70nSAVlDuJaZ8h6seb6zR4z09PZk7PyDcoyh09UMN75B9TZthr7Nnfiu9c5T6SKBFW0Tkzi3558F92z01j77JO46fmfoWfguPH9sCc2WdNJGzYYF4Lubu/nmakes8eMeVzmoC6rcYhKhsG/QJ1tq/GRZSsqfRiOWtON3H5y2QoM1tdBkelY2jNwPNxB0UQC6Ox0/p5XHt8c7M3XY4aISoJpnyL86CM349Zf/2+8NXqh0ocypyGVQteRfnSvXZkzyWs8lUL3y79Dp9edf5Dyy7VrjSD9+OO5aZpNm3K7ZJqsk7FqqccMWyRTleCdf5F+8a83VzQF9JFlKzLtKSYm51b0clvMfajO43pfV2cEbb8tLQ4fzgTp4WHgiSeABx4weukcPAhcfnnmE4CI8bi52bgo7NhhBMtaab1gT1+ZnUP7+ip7XEQOeOcfgs621ejavxepoLNViyAAvnPdxuzWFH19wKFjAICW6RkMOjRya7H3/bH2uLfeqba3Az09mRbIfs3OZrpnDg8Do6NGWeaGDe7941evdr7Lv+qqYO9daWyRTFWEwT8kNyxdjn85+25Z3qshmXRsQGetfumyrVIGZFJCWcbHjRJQO3slzY4dhaVhrMHPLTi+/bbzc91aNeRTybRLLaWvqOYx7ROS42OjZXmfpMjcamNz1TsOcjqWui3y7je14tQB0i9rGsSJ2yemoEGz0mmXWklfUSww+IekXH2AzNRSVvWOi8621Xjxlj/GkU99Gi+2fxCdw+9l7xBkRqzTpCq/k7qsz3ESVquGSlcNsUUyVRGmfUJSifV+resNewqjq6XTpCrrpK6GBmPymHVdZGvwc2ur3NFhrNJVbLvlSqdd2DmUqgiDf0icVgWzSgC4LH2BECC0lcECfeIoxYxY+2vmy7nnC45hrJ0bhZWpOOuYqgSDf0jMu2+3Bd9nAbx4yx8DMFpEdL9xAEPjY2hpaMTNF1+KF06/g6HxMSyuq8PoTMr3OgKR6zzqFfzcvh9G0OSCLUS+MfiHqLNtNbrfOOCa/rnp+Z+ha936vKuHAbkXh9GZacdeQgJkrTcce0y7EPkmWsba9CA6Ojq0t7e30ocRWI9DiaWVa5lmHmuffdI1TXT0U58u4CiJqFaJSJ+qdnjtV1S1j4gsFZFfishb6X+XOOxzrYi8JCKvicirIvInxbxn1FlLLJ2Yg7RBuKV23N6DiMhLsaWe9wL4lapeAeBX6cd2YwD+var+KwCbAfxXEanpwmezxNKtrVnQstCudevRYOvT05BMMuVDRAUrNvjfBuD76a+/DyCnvaOqvqmqb6W/HgJwGkA022GGzO2OPeggbc6ErYbGwKkjIiKrYoP/Jap6EgDS/16cb2cR2QigHoDLfP7aEuYde2fbanStW4+WhkYMjY95zvAlIsrHs9pHRJ4HcKnDt74S5I1E5DIAPwRwp6pzHaOI3AXgLgBYtWpVkJePJPPO3Fq5Y1b7BGUfSDZn+Frfh4jIr6KqfUTkEICbVfVkOri/oKofdNjvIgAvAPiWqj7p57WrtdqnVG56/meOJaStDY1z8weIiMpS7QNgF4A701/fCeAZhwOpB/DPAH7gN/BTLrdB4nL1FCKi2lJs8P8bAJ8UkbcAfDL9GCLSISKPpff5DICPAficiOxP/3dtke8bO2ENHhMRAUXO8FXVswA+4bC9F8Cfpb/+RwD/WMz7kHPvIJZ7ElGh2N6hSoQ5eExExOBfRbx6AhER+cXFXIiIYoh3/iGxd+JkSoaIoozBPwScgEVE1YZpnxB0v3Egp4VzId07iYjKhcE/BJyARUTVhsE/BJyARUTVhsE/BOy3T0TVhgO+IeAELCKqNgz+IeEELCKqJkz7EBHFEIM/EVEMMfgTEcUQgz8RUQwx+BMRxRCDPxFRDDH4ExHFEIM/EVEMiapW+hgcicgFAIcqfRwVsBzAmUofRAXE8bzjeM4Az7vUVqvqCq+dojzD95CqdlT6IMpNRHp53vEQx3MGeN6VPg4T0z5ERDHE4E9EFENRDv6PVvoAKoTnHR9xPGeA5x0JkR3wJSKi0onynT8REZVIZIK/iCwVkV+KyFvpf5c47HOtiLwkIq+JyKsi8ieVONYwiMhmETkkIodF5F6H788XkSfS339ZRNrLf5Th8nHOd4vI6+nf7a9EpCYWSPA6b8t+t4uIikhkKkKK4ee8ReQz6d/5ayLyT+U+xrD5+H98lYj8RkT2pf8//6NKHCcAQFUj8R+AhwDcm/76XgDfdtjnSgBXpL9uAXASQHOlj72Ac00CeBvAWgD1AP4fgKtt+/xHAP8j/fV2AE9U+rjLcM5/CKAx/fVfVvs5+z3v9H6LAPwfAHsAdFT6uMv0+74CwD4AS9KPL670cZfhnB8F8Jfpr68GcKxSxxuZO38AtwH4fvrr7wPotO+gqm+q6lvpr4cAnAbgOZkhgjYCOKyqR1R1CsBOGOdvZf15PAXgEyIiZTzGsHmes6r+RlXH0g/3AGgr8zGWgp/fNQB8A8YN0EQ5D66E/Jz3nwN4RFXPA4Cqni7zMYbNzzkrgIvSXy8GMFTG48sSpeB/iaqeBID0vxfn21lENsK4ur5dhmMLWyuAfsvjgfQ2x31UdQbACIBlZTm60vBzzlafB7C7pEdUHp7nLSLXAVipqj8t54GVmJ/f95UArhSR34nIHhHZXLajKw0/5/w1AJ8VkQEAzwH4T+U5tFxlneErIs8DuNThW18J+DqXAfghgDtVdTaMYyszpzt4e9mVn32qie/zEZHPAugA8PGSHlF55D1vEUkA+C6Az5XrgMrEz+97HozUz80wPuX9VkTWq+pwiY+tVPyc8x0A/peq/q2I3Ajgh+lzLnscK2vwV9Vb3L4nIqdE5DJVPZkO7o4fAUXkIgA/A3C/qu4p0aGW2gCAlZbHbcj9+GfuMyAi82B8RDxXnsMrCT/nDBG5BcbNwMdVdbJMx1ZKXue9CMB6AC+ks3qXAtglIltVtbdsRxk+v/+P71HVaQBHReQQjIvB3vIcYuj8nPPnAWwGAFV9SUQWwOj5U/aUV5TSPrsA3Jn++k4Az9h3EJF6AP8M4Aeq+mQZjy1sewFcISJr0ue0Hcb5W1l/HrcD+LWmR4mqlOc5p9Mf3wOwtQbyv6a8562qI6q6XFXbVbUdxlhHtQd+wN//4z0wBvkhIsthpIGOlPUow+XnnE8A+AQAiMhVABYAeLesR2mq9Ai5ZRR8GYBfAXgr/e/S9PYOAI+lv/4sgGkA+y3/XVvpYy/wfP8IwJswxiy+kt72IIw/fMD4n+JJAIcBvAJgbaWPuQzn/DyAU5bf7a5KH3M5ztu27wuogWofn79vAfAdAK8D+D2A7ZU+5jKc89UAfgejEmg/gFsrdayc4UtEFENRSvsQEVGZMPgTEcUQgz8RUQwx+BMRxRCDPxFRDDH4ExHFEIM/EVEMMfgTEcXQ/wft51H1zUsR6wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#K means\n",
    "num_clusters = 3\n",
    "num_seeds = 10\n",
    "max_iterations = 300\n",
    "labels_color_map = {\n",
    "    0: '#20b2aa', 1: '#ff7373', 2: '#ffe4e1'}\n",
    "pca_num_components = 2\n",
    "tsne_num_components = 2\n",
    "\n",
    "# texts_list = some array of strings for which TF-IDF is being computed\n",
    "# calculate tf-idf of texts\n",
    "# create k-means model with custom config\n",
    "x_train_corrected = [\" \".join(x) for x in x_train]\n",
    "\n",
    "vectorizer=TfidfVectorizer(min_df=1,max_df=0.5,stop_words='english', decode_error='ignore')\n",
    "tf_idf_matrix = vectorizer.fit_transform(x_train_corrected)\n",
    "clustering_model = KMeans(\n",
    "    n_clusters=num_clusters,\n",
    "    max_iter=max_iterations,\n",
    "    precompute_distances=\"auto\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "labels = clustering_model.fit_predict(tf_idf_matrix)\n",
    "# print labels\n",
    "\n",
    "X = tf_idf_matrix.todense()\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "reduced_data = PCA(n_components=pca_num_components).fit_transform(X)\n",
    "print(reduced_data)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for index, instance in enumerate(reduced_data):\n",
    "    # print instance, index, labels[index]\n",
    "    pca_comp_1, pca_comp_2 = reduced_data[index]\n",
    "    color = labels_color_map[labels[index]]\n",
    "    ax.scatter(pca_comp_1, pca_comp_2, c=color)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# t-SNE plot\n",
    "embeddings = TSNE(n_components=tsne_num_components)\n",
    "Y = embeddings.fit_transform(X)\n",
    "plt.scatter(Y[:, 0], Y[:, 1], cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naive's Bayes\n",
    "pipeline_NB = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', OneVsRestClassifier(MultinomialNB(\n",
    "        fit_prior=True, class_prior=None))),\n",
    "])\n",
    "parameters_NB = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    'clf__estimator__alpha': (1e-2, 1e-3)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1156,  271],\n",
       "       [ 221, 3107]], dtype=int64)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SVM\n",
    "pipeline_SVM = Pipeline(\n",
    "    [\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', OneVsRestClassifier(LinearSVC()))])\n",
    "parameters_SVM = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    \"clf__estimator__C\": [0.01, 0.1, 1],\n",
    "    \"clf__estimator__class_weight\": ['balanced', None],\n",
    "}\n",
    "confusion_matrix(y_test, predictions, labels=[\"vldb\", \"icse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1156,  271],\n",
       "       [ 221, 3107]], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "pipeline_logistic = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words=stop_words)),\n",
    "    ('clf', OneVsRestClassifier(LogisticRegression(solver='sag')))])\n",
    "parameters_logistic = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'tfidf__ngram_range': [(1, 1), (1, 2), (1, 3)],\n",
    "    \"clf__estimator__C\": [0.01, 0.1, 1],\n",
    "    \"clf__estimator__class_weight\": ['balanced', None],\n",
    "}\n",
    "confusion_matrix(y_test, predictions, labels=[\"vldb\", \"icse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
